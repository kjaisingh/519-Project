{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "519-Final-Project-Brendan.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCNlJQHz-lzq"
      },
      "source": [
        "# Imports + Notebook Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAy64-Xk-oIy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "e268418d-d6c3-4998-be34-fb450d149798"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "import keras\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.layers import Input, Dense, Bidirectional, Dropout, GlobalAveragePooling1D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from bioinfokit.visuz import cluster"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-02e065691f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbioinfokit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbioinfokit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisuz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bioinfokit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mFVaLKXV7Ru"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgcGeQTnV-Jx"
      },
      "source": [
        "btc_meta = pd.read_csv('Bitcoin-Metadata.csv')\n",
        "btc_meta = btc_meta.drop(['SNo', 'Name', 'Symbol', 'Date'], axis = 1)\n",
        "btc_meta_r = btc_meta.copy()\n",
        "\n",
        "def f(x):\n",
        "  if (x['Close2'] > x['Close']):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "btc_meta_c = btc_meta.copy()\n",
        "btc_meta_c['Direction'] = btc_meta_c.apply(f, axis = 1)\n",
        "btc_meta_c = btc_meta_c.drop(btc_meta_c.columns[-2], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMqvR-Fzyj3l"
      },
      "source": [
        "# LSTM - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP8UFKUw7OEj"
      },
      "source": [
        "## Structuring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gLXS9Wxx4YQ"
      },
      "source": [
        "#getting the price-related features from the dataframe\n",
        "features = btc_meta_c[['High', 'Low', 'Open', 'Close', 'Rel_Close', 'HL_Ratio', \n",
        "                       'Rel_High', 'Rel_Low', 'SMA7', 'SMA30', 'SMA60', \n",
        "                       'SMA90', 'SMA200']].values\n",
        "X_temp = np.array(features)\n",
        "y_temp = np.array(btc_meta_c['Direction'])\n",
        "\n",
        "# make X_train a 3 dimensional array for LSTM input shape\n",
        "n_instances = X_temp.shape[0]\n",
        "n_features = X_temp.shape[1]\n",
        "n_lookback = 90\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(n_instances - n_lookback):\n",
        "    X.append(X_temp[i: i + n_lookback, :])\n",
        "    y.append(y_temp[i + n_lookback])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly4hr855vdYM"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz0Giz4jym9_"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape = (n_lookback, n_features), return_sequences = True))\n",
        "model.add(LSTM(256, dropout = 0.2, recurrent_dropout = 0.2, return_sequences = True))\n",
        "model.add(LSTM(128, dropout = 0.2, recurrent_dropout = 0.2, return_sequences = True))\n",
        "model.add(LSTM(64, dropout = 0.2, recurrent_dropout = 0.2, return_sequences = True))\n",
        "model.add(LSTM(16, dropout = 0.1, recurrent_dropout = 0.1, return_sequences = False))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', \n",
        "              optimizer = 'adam', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRWWwUXvKIaV"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q5itJQ-yvql"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size = 64,\n",
        "          epochs = 5, validation_split = 0.05,\n",
        "          callbacks = [EarlyStopping(patience = 2)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUG82Tm21t2w"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3EwZ4RJ1vMs"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkqAL4Dt3Otn"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
        "lstm_metrics = (accuracy_score(y_test, y_pred), \n",
        "                f1_score(y_test, y_pred, average = 'binary'))\n",
        "lstm_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jjV7wEtvloE"
      },
      "source": [
        "# LSTM - Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUaTwMNx7Zmj"
      },
      "source": [
        "## Structuring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbkxT3vc7Zmk"
      },
      "source": [
        "X_temp = np.array(btc_meta_c.iloc[:, :-1])\n",
        "y_temp = np.array(btc_meta_r['Close2'])\n",
        "\n",
        "# make X_train a 3 dimensional array for LSTM input shape\n",
        "n_instances = X_temp.shape[0]\n",
        "n_features = X_temp.shape[1]\n",
        "n_lookback = 90\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(n_instances - n_lookback):\n",
        "    X.append(X_temp[i: i + n_lookback, :])\n",
        "    y.append(y_temp[i + n_lookback])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aozrbFIf7Zmk"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D1xSieH7Zmk"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape = (n_lookback, n_features), return_sequences = True))\n",
        "model.add(LSTM(256, dropout = 0.2, recurrent_dropout = 0.2, return_sequences = True))\n",
        "model.add(LSTM(128, dropout = 0.2, recurrent_dropout = 0.2, return_sequences = True))\n",
        "model.add(LSTM(64, dropout = 0.2, recurrent_dropout = 0.2, return_sequences = True))\n",
        "model.add(LSTM(16, dropout = 0.1, recurrent_dropout = 0.1, return_sequences = False))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss = 'mean_absolute_error', \n",
        "              optimizer = 'adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3VKWY4i7Zmk"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjS1B6RA7Zml"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size = 128,\n",
        "          epochs = 8, validation_split = 0.05,\n",
        "          callbacks = [EarlyStopping(patience = 2)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hipQv_r0vrjH"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLOKaYi-vrjH"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TThCpgG7vrjH"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = [x for x in y_pred]\n",
        "lstm_metrics = (mean_absolute_error(y_test, y_pred), \n",
        "                r2_score(y_test, y_pred))\n",
        "lstm_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnNGdMid9c8H"
      },
      "source": [
        "# CNN - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9tJz9WK9c8H"
      },
      "source": [
        "## Structuring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aXrqDoT9c8H"
      },
      "source": [
        "# getting the price-related features from the dataframe\n",
        "features = btc_meta_c[['High', 'Low', 'Open', 'Close', 'Rel_Close', 'HL_Ratio', \n",
        "                       'Rel_High', 'Rel_Low', 'SMA7', 'SMA30', 'SMA60', \n",
        "                       'SMA90', 'SMA200']].values\n",
        "X_temp = np.array(features)\n",
        "y_temp = np.array(btc_meta_c['Direction'])\n",
        "\n",
        "# make X_train a 3 dimensional array for CNN input shape\n",
        "n_instances = X_temp.shape[0]\n",
        "n_features = X_temp.shape[1]\n",
        "n_lookback = 90\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(n_instances - n_lookback):\n",
        "    X.append(X_temp[i: i + n_lookback, :])\n",
        "    y.append(y_temp[i + n_lookback])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmb0Fp6Z9c8I"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxHtC1bB9c8I"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(1, 50, activation='relu', input_shape = (n_lookback, n_features)))\n",
        "for rate in (1, 2, 4, 8) * 2:\n",
        "    model.add(Conv1D(filters = 20, kernel_size = 2, padding = 'causal',\n",
        "                      activation = 'relu', dilation_rate = rate))\n",
        "    model.add(Dropout(0.1))\n",
        "model.add(Conv1D(filters = 10, kernel_size = 1))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', \n",
        "              optimizer = 'adam', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq89ywS-9c8J"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqLTeHIV9c8J"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size = 64,\n",
        "          epochs = 20, validation_split = 0.05,\n",
        "          callbacks = [EarlyStopping(patience = 5)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXvfSQOZ9c8J"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAgon9Ag9c8K"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0J-VBoQ9c8K"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
        "cnn_metrics = (accuracy_score(y_test, y_pred), \n",
        "              f1_score(y_test, y_pred, average = 'binary'))\n",
        "cnn_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sftQTb1VBSys"
      },
      "source": [
        "# CNN - Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abY2KyU5BSys"
      },
      "source": [
        "## Structuring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpzHr7NkBSys"
      },
      "source": [
        "X_temp = np.array(btc_meta_c.iloc[:, :-1])\n",
        "y_temp = np.array(btc_meta_r['Close2'])\n",
        "\n",
        "# make X_train a 3 dimensional array for CNN input shape\n",
        "n_instances = X_temp.shape[0]\n",
        "n_features = X_temp.shape[1]\n",
        "n_lookback = 90\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(n_instances - n_lookback):\n",
        "    X.append(X_temp[i: i + n_lookback, :])\n",
        "    y.append(y_temp[i + n_lookback])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgtiFWaFBSyu"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlFy6J3RBSyu"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(1, 50, activation='relu', input_shape = (n_lookback, n_features)))\n",
        "for rate in (1, 2, 4, 8) * 2:\n",
        "    model.add(Conv1D(filters = 20, kernel_size = 2, padding = 'causal',\n",
        "                      activation = 'relu', dilation_rate = rate))\n",
        "    model.add(Dropout(0.1))\n",
        "model.add(Conv1D(filters = 10, kernel_size = 1))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(10))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss = 'mean_absolute_error', \n",
        "              optimizer = 'adagrad')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLiqKkEhBSyu"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gcU5UYjBSyv"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size = 64,\n",
        "          epochs = 100, validation_split = 0.05,\n",
        "          callbacks = [EarlyStopping(patience = 20)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDQMOj2VBSyw"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnkMSAK9BSyw"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz_KOuIgBSyw"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = [x for x in y_pred]\n",
        "cnn_metrics = (mean_absolute_error(y_test, y_pred), \n",
        "               r2_score(y_test, y_pred))\n",
        "cnn_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdS9qsg3PXvv"
      },
      "source": [
        "# Further Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER_htHgeP5S-"
      },
      "source": [
        "## Downscaling the Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj00M_-6Q8YV"
      },
      "source": [
        "Our current price prediction model uses 90 days of historical prices to predict the next-day price, creating a memory-intensive operation given both the number of rows and columns in the training dataste. Furthermore, we know that days far before the next day are likely to be less significant that days closer to it. As a result, we can apply some dimensionality reduction techniques and see whether or not our optimised regression model still maintains its performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87w0X-X6AbIY"
      },
      "source": [
        "# getting the price-related features from the dataframe\n",
        "features = btc_meta_c[['High', 'Low', 'Open', 'Close', 'Rel_Close', 'HL_Ratio', \n",
        "                       'Rel_High', 'Rel_Low', 'SMA7', 'SMA30', 'SMA60', \n",
        "                       'SMA90', 'SMA200']].values\n",
        "X_temp = np.array(features)\n",
        "y_temp = np.array(btc_meta_c['Direction'])\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_temp = sc.fit_transform(X_temp)\n",
        "\n",
        "pca = PCA()\n",
        "pca = pca.fit(X_temp)\n",
        "var = pca.explained_variance_\n",
        "num = pca.n_features_\n",
        "names = [str(i) for i in list(range(1, num + 1))]\n",
        "cluster.screeplot(obj = [names, pca.explained_variance_ratio_], dim = (18, 5), show = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HW1RRapbtgN"
      },
      "source": [
        "pca = PCA(n_components = 6)\n",
        "pca = pca.fit(X_temp)\n",
        "X_temp = pca.transform(X_temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgcXNahSbmPU"
      },
      "source": [
        "n_instances = X_temp.shape[0]\n",
        "n_features = X_temp.shape[1]\n",
        "n_lookback = 90\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(n_instances - n_lookback):\n",
        "    X.append(X_temp[i: i + n_lookback, :])\n",
        "    y.append(y_temp[i + n_lookback])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O87p_PKwD7xJ"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(1, 50, activation='relu', input_shape = (n_lookback, n_features)))\n",
        "for rate in (1, 2, 4, 8) * 2:\n",
        "    model.add(Conv1D(filters = 20, kernel_size = 2, padding = 'causal',\n",
        "                      activation = 'relu', dilation_rate = rate))\n",
        "    model.add(Dropout(0.1))\n",
        "model.add(Conv1D(filters = 10, kernel_size = 1))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', \n",
        "              optimizer = 'adam', \n",
        "              metrics = ['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size = 64,\n",
        "        epochs = 20, validation_split = 0.05,\n",
        "        callbacks = [EarlyStopping(patience = 5)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjYZpMG8D7xJ"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
        "cnn_metrics = (accuracy_score(y_test, y_pred), \n",
        "               f1_score(y_test, y_pred, average = 'binary'))\n",
        "cnn_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zwdw2jHQe5B"
      },
      "source": [
        "## Extending to Other Cryptocurrencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFOlcnzmFYkc"
      },
      "source": [
        "eth_meta = pd.read_csv('Ethereum-Metadata.csv')\n",
        "eth_meta = eth_meta.drop(['SNo', 'Name', 'Symbol', 'Date'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7xl1CTxFYkq"
      },
      "source": [
        "def f(x):\n",
        "  if (x['Close2'] > x['Close']):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "eth_meta['Direction'] = eth_meta.apply(f, axis = 1)\n",
        "eth_meta = eth_meta.drop(['Close2'], axis = 1)\n",
        "\n",
        "eth_meta.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4L3Fe3SGcpQ"
      },
      "source": [
        "features = eth_meta[['High', 'Low', 'Open', 'Close', 'Rel_Close', 'HL_Ratio', \n",
        "                       'Rel_High', 'Rel_Low', 'SMA7', 'SMA30', 'SMA60', \n",
        "                       'SMA90', 'SMA200']].values\n",
        "X_temp = np.array(features)\n",
        "y_temp = np.array(eth_meta['Direction'])\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_temp = sc.fit_transform(X_temp)\n",
        "\n",
        "n_instances = X_temp.shape[0]\n",
        "n_features = X_temp.shape[1]\n",
        "n_lookback = 90\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(n_instances - n_lookback):\n",
        "    X.append(X_temp[i: i + n_lookback, :])\n",
        "    y.append(y_temp[i + n_lookback])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvwk1LggdvVu"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYcCaUQpGcpR"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(1, 50, activation='relu', input_shape = (n_lookback, n_features)))\n",
        "for rate in (1, 2, 4, 8) * 2:\n",
        "    model.add(Conv1D(filters = 20, kernel_size = 2, padding = 'causal',\n",
        "                      activation = 'relu', dilation_rate = rate))\n",
        "    model.add(Dropout(0.1))\n",
        "model.add(Conv1D(filters = 10, kernel_size = 1))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', \n",
        "              optimizer = 'adam', \n",
        "              metrics = ['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size = 64,\n",
        "          epochs = 20, validation_split = 0.05,\n",
        "          callbacks = [EarlyStopping(patience = 5)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyaHto5LGmsM"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
        "cnn_metrics = (accuracy_score(y_test, y_pred), \n",
        "               f1_score(y_test, y_pred, average = 'binary'))\n",
        "cnn_metrics"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}